### Make new contributions here!!
# ğŸ¨ Emotion-Based Music Recommendation â€“ Gradio UI

This module provides a simple, beautiful, and interactive **frontend interface** using [Gradio](https://www.gradio.app/) to simulate music recommendations based on emotions detected from user-uploaded or webcam images.

---

## ğŸš€ How It Works

1. The user uploads or captures an image via webcam.
2. A dummy emotion detection function randomly selects one emotion from:
   - ğŸ˜„ Happy
   - ğŸ˜¢ Sad
   - ğŸ˜  Angry
   - ğŸ˜ Neutral
   - ğŸ˜² Surprised
3. Based on the detected emotion, a matching music playlist is recommended with emojis for an enhanced UX.

---

## ğŸ–¥ï¸ Preview

> Once the server is running, the UI looks like this:


ğŸ¼ Emotion-based Music Recommendation

Upload your image or take a webcam photo to get music recommendations based on your emotion!
code/new_models/Screenshot 2025-07-23 at 1.18.39â€¯PM.png
code/new_models/Screenshot 2025-07-23 at 1.19.05â€¯PM.png
code/new_models/Screenshot 2025-07-23 at 1.19.31â€¯PM.png



---

## ğŸ› ï¸ How to Run the UI

### 1. Activate your virtual environment

```bash
source venv/bin/activate

2. Navigate to the UI directory
cd code/new_models/

3. Run the Gradio app
python frontend_gradio_ui.py

4. Open the app in browser

Visit:
http://127.0.0.1:7860

ğŸ§¾ Requirements
Install Gradio (if not already installed):
pip install gradio

You can also install all project dependencies via:
pip install -r requirements.txt

ğŸ“ Project Structure
code/
â””â”€â”€ new_models/
    â”œâ”€â”€ frontend_gradio_ui.py   # Main Gradio UI file
    â””â”€â”€ README_UI.md            # Documentation (this file)
ğŸ‘©â€ğŸ’» Developer Note
This frontend does not use actual facial emotion recognition logic yet â€” instead, it simulates detection with random choices for demonstration purposes. You can easily plug in a real model into the detect_emotion(image) function.


ğŸ™‹â€â™€ï¸ Contributor
Developed with â¤ï¸ by @Sanskriti10247
As part of GirlScript Summer of Code 2025

ğŸ“„ License
This project is licensed under the MIT License.